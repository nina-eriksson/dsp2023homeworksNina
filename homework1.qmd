---
title: "Homerwork 1"
author: "Nina Ferrer-Eriksson"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

```{r}
#| label: problem-1
dplyr::glimpse(flights)
# Had an arrival delay of two or more hours (> 120 minutes)
flights %>% 
  filter(!is.na(dep_time)) %>% 
   filter(arr_delay > 120)

  
# Flew to Houston (IAH or HOU)
flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(dest %in% c("IAH" , "HOU"))

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(carrier %in% c("UA" , "AA" , "DL"))

# Departed in summer (July, August, and September)
flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(month %in% c("6" , "7" , "8"))
  
# Arrived more than two hours late, but didn't leave late
flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(dep_delay <= 0  , arr_delay > 120)

# Were delayed by at least an hour, but made up over 30 minutes in flight
flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(dep_delay >= 60 , arr_delay <= dep_delay - 30)
```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
flights %>% 
  filter(is.na(dep_time)) 
```

```{r}
#| label: problem-2
# What months had the highest and lowest % of cancelled flights?
flights %>% 
  filter(is.na(dep_time)) %>% 
  group_by(month) %>% 
  summarise(cancelled_count = n()) %>%
  mutate(cancelled_percentage = cancelled_count / sum(cancelled_count)) %>%
  arrange(cancelled_percentage) 
  
# The month with the highest % of cancelled flights is February and the month with the lowest % of cancelled flights is November.

flights %>%
  group_by(month) %>%
  summarise(total_flights = n()) %>% 
  arrange(desc(total_flights))

# After counting for the total number of flights per month, it seems that November and February are amongst the months with the lowest total number of flights. November is at the beginning of the winter season whereas February is in the middle of it. November also corresponds with major US holidays such as Thanksgiving, where you would expect many people to fly to join their families, which could help explain why this month has the lowest % of cancelled flights. There are no major celebration in February, which could explain why this month has the highest % of cancelled flights. 

```

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}
# I use the str() function to quickly examine the datasets
str(flights)
str(planes)

# first I filter for the year 2013
y2013 <- flights %>% 
  filter(!is.na(dep_time)) %>% 
  filter(year == 2013) %>%
  
# I then count the number of flights for each tailnum and arrange the results in descending order  
  group_by(tailnum) %>%
  summarise(total_flights = n()) %>%
  arrange(desc(total_flights))
  
# The plane that traveled the most times from NYC airports in 2013 is N725MQ, but it does not seem to be in the planes dataset.  
  
# I use the left_join() function to create the desired table  
  left_join(y2013, planes, by = "tailnum")
  
 

# I find the plane with the greatest number of flights and more than 50 seats
maxplane <- planes %>% 
  filter(!is.na(seats)) %>%
  filter(seats >= 50) 
maxplane

# I then look at the y2013 data frame to find which plane with more than 50 seats has the greatest number of flights, and I find that it is plane N328AA.

# I now create a table to show where the plane N328AA has flown to in 2013.
N328plane <- flights %>% 
  filter(!is.na(dep_time)) %>%
  filter(year == 2013, tailnum == "N328AA") %>% 
  group_by(dest) %>% 
  summarise(total_flights = n())

# I print the results
print(maxplane)
print(N328plane)
```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

\

```{r}
# I use the str() function and the smik() function to quickly examine the dataset
str(weather)
skimr::skim(weather)
skimr::skim(weather$temp)

# -   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
temperature <- weather %>% 
  filter(month == 7, year == 2013) %>%
  arrange(desc(temp))
  
temperature

summary(temperature)

# The mean temperature is around 80 degrees and the median is around 79 degrees Fahrenheit. The highest temperature is around 100 and the lowest around 64. 

# I represent the distribution of the temperature in a plot to better visualise and understand the data. 
temp_plot <- temperature %>% 
   ggplot(aes(x = temp)) +
  geom_histogram() +
  labs(title = "Distribution of Temperature in July 2013",
       x = "Temperature (°F)",
       y = "Frequency")

temp_plot

temp_windspeed <- temperature %>% 
  ggplot(aes(x = "", y = wind_speed)) +
  geom_boxplot() +
  labs(title = "Boxplot of Wind Speed in July 2013",
       x = "",
       y = "Wind Speed")

temp_windspeed

# The outliers are wind speeds over 20. Looking at the corresponding temperature, the windiest days happened when the temperature was close to the mean temperature in July, so it does not seem that there is any relationship between temperature and wind speed. 

# -   What is the relationship between `dewp` and `humid`?
dewp_humid_plot <- weather %>%
  ggplot(aes(x = dewp, y = humid)) +
  geom_point() +
  labs(title = "Relationship between Dew Point and Humidity",
       x = "Dew Point (°F)",
       y = "Humidity (%)")

dewp_humid_plot

# I look at the correlation to get a clearer idea of the relationship between both variables. I remove any missing values first.

cleanweather1 <- weather %>% 
    filter(!is.na(dewp)) %>%
    filter(!is.na(humid))

correlation1 <- cor(cleanweather1$dewp, cleanweather1$humid)
correlation1

# The correlation between Dew Point and Humidity is moderately positive, 0.51. Therefore, it is likely that the Dew Point is with higher humidity, but humidity does not explain it all. 

#-   What is the relationship between `precip` and `visib`?
precip_visib_plot <- weather %>%
  ggplot(aes(x = visib, y = precip)) +
  geom_point() +
  labs(title = "Relationship between Visibility and Precipitation",
       x = "Visibility (miles)",
       y = "Precipitation (inches)")

precip_visib_plot

# I look at the correlation to get a clearer idea of the relationship between both variables. I remove any missing values first.

cleanweather2 <- weather %>% 
    filter(!is.na(precip)) %>%
    filter(!is.na(visib))

correlation2 <- cor(cleanweather2$precip, cleanweather2$visib)
correlation2

# There is a small negative correlation between Precipitation and Visbility of -0.32. So it appears that rain does not impact visibility. 
```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}
# -   How many planes have a missing date of manufacture?
# I start by quickly examining the data
str(planes)
str(flights)

# I am assuming that the column "year" corresponds to the data of manufacture of the plane
missing <- planes %>% 
  summarise(count = sum(is.na(year)))

missing

# 70 planes have a missing date of manufacture. 

#-   What are the five most common manufacturers?
planes %>% 
  group_by(manufacturer) %>% 
  summarise(manufacturer_type=n()) %>% 
  arrange(desc(manufacturer_type))

# The 5 most common manufacturers are: Boeing, Airbus, Bombardier, Embraer and McDonell Douglas


#-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)


# I merge the two data sets to be able to compare manufacturers with the airplanes flying.
planesflights <- left_join(flights, planes, by = "tailnum")
planesflights

# I now use the case_when() function to recode the manufacturer name and collapse rare vendors into a category called Other:
merged <- planesflights %>%
  group_by(manufacturer) %>%
  summarise(count = n()) %>%
  mutate(manufacturer_type = case_when(
    count < 100 ~ "Other",
    TRUE ~ as.character(manufacturer)
  )) %>%
# I have now renamed all the manufacturers that produced less than 100 planes as "Other", I now need to group all the manufacturers renamed "Other" into one single group:
  group_by(manufacturer_type) %>%
  summarise(count = sum(count))

merged

joined_data <- left_join(planesflights, merged, by = c("manufacturer" = "manufacturer_type"))


  
# I now look at the distribution of manufacturer in 2013
manufacturer_counts <- joined_data %>%
  group_by(month, manufacturer) %>%
  summarise(count = n()) %>%
  arrange(month, desc(count))

manufacturer_counts

# By looking at the table able, it looks like in 2013, the distribution of manufacturers over time is very consistent, with Boeing, Embraer and Airbus being top 3 in this respective order across all the months of 2013.
```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}
#-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
# I take a look at the data
str(flights)
str(planes)

# I use the arrange function to find the oldest plane
oldestplane <- planes %>%
  arrange(year) 

oldestplane

# The oldest plane's tailnum is N381AA, manufactured in the year 1956.

#-   How many airplanes that flew from New York City are included in the planes table?
NYCplanes <- planesflights %>%
  filter(!is.na(tailnum)) %>% 
  group_by(tailnum)

NYCplanes

# There are 3,322 airplanes that flew from NYC included in the planes table

```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}
# -   What is the median arrival delay on a month-by-month basis in each airport?
str(flights)

median_delay <- flights %>%
  group_by(month, origin) %>%
  summarize(median_arr_delay = median(arr_delay, na.rm = TRUE))

median_delay

# -   For each airline, plot the median arrival delay for each month and origin airport.
# I represent each airport in a different plot to have a better idea of the data. I put months as the x-axis and median arrival delay on the y-axis.
airportsplot <- ggplot(median_delay, aes(x = month, y = median_arr_delay)) +
  geom_line() +
  facet_wrap(~origin, ncol = 1) +
  labs(x = "Month", y = "Median Delay", title = "Median Arrival Delay by Month and Origin")

airportsplot  



```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}
# I quickly examine the datasets to see where I could join the data together in a table
str(flights)
str(airlines)

# I join the datasets by the column they have in common, which is the carrier column
airlinesflights <- left_join(airlines, flights, by = "carrier")
airlinesflights

# I count which airlines flew the most to SFO
SFOflights <- airlinesflights %>% 
  group_by(carrier, dest, name) %>% 
  filter(dest == "SFO") %>% 
  summarize(count = n()) %>% 
  arrange(desc(count))

SFOflights

# United Airlines is the airline that flew the most to SFO, followed by Virgin America and Delta Airlines


# I now produce the required dataframe and use the sum () function to calculate the total number of trips that airlines flew to SFO

sumSFOflights <- sum(SFOflights$count)
sumSFOflights

fly_into_sfo <- SFOflights %>% 
  mutate(percent = count / 13331 * 100) %>% 
  group_by(name, count, percent)

fly_into_sfo

```

And here is some bonus ggplot code to plot your dataframe

```{r}
#| label: ggplot-flights-toSFO
#| message: false
#| warning: false

fly_into_sfo %>% 
  
  # sort 'name' of airline by the numbers it times to flew to SFO
  mutate(name = fct_reorder(name, count)) %>% 
  
  ggplot() +
  
  aes(x = count, 
      y = name) +
  
  # a simple bar/column plot
  geom_col() +
  
  # add labels, so each bar shows the % of total flights 
  geom_text(aes(label = percent),
             hjust = 1, 
             colour = "white", 
             size = 5)+
  
  # add labels to help our audience  
  labs(title="Which airline dominates the NYC to SFO route?", 
       subtitle = "as % of total flights in 2013",
       x= "Number of flights",
       y= NULL) +
  
  theme_minimal() + 
  
  # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
  # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
  
  theme(#
    # so title is left-aligned
    plot.title.position = "plot",
    
    # text in axes appears larger        
    axis.text = element_text(size=12),
    
    # title text is bigger
    plot.title = element_text(size=18)
      ) +

  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))

# To create the plot below, I would:
# Use the cancellations dataset and assign it to a new name, say "Cancellations_plot"
# Use the ggplot () function to create the plot. Within the ggplot() function, I would:
# Use aes() and assign months to the x-axis and the number of cancellations to the y-axis
# Use the facet_wrap () function to separate by airline and by airport (JFK and EWR)
# Use geom_historgram () to have the data represented in the same style as the plot, and specify that the number of cancelled flights per month should be written in each bar
# Use the labs() function to assign titles: "Cancellations of flights to SFO by month, carrier and airport origin
# Use the case_when() function to replace the numbers used to denot the different months of the year by their shortened names (e.g. replacing 1 from the month column by "Jan")
```

I want you to think how we would organise our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

![](images/sfo-cancellations.png)

## Problem 10: On your own -- Hollywood Age Gap

The website https://hollywoodagegap.com is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:-----------|:-----------|:-----------------------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')

# I explore the dataset
str(age_gaps)

# I create a new column with the age difference using the mutate() function
age_difference <- age_gaps %>% 
  mutate(age_diff = actor_1_age - actor_2_age)

age_difference   

# I now check how distributed the age gaps are
summary(age_difference$age_diff)

# The mean age difference is around 10 years, the lowest is 0 (no age difference) and the highest is 52 years.

# I now check if the mean age difference has varies over time using the movies' release dates
age_over_time <- age_difference %>% 
  ggplot(aes( x = release_year, y = age_diff)) +
  geom_point(alpha = 0.5) +
  labs(x = "Release Year", y = "Age Gap", title = "Age Gap over Time") +
  theme_minimal()

age_over_time

# It is hard to easily visualize data trends so I check the correlation
cor(age_difference$release_year, age_difference$age_diff)

# The correlation is weakly negatively correlated (-0.2), meaning that the more recent the movie is, the slighlty lower the age gap between actors is. 

# I want to check the half plus seven rule of the age gap in movies to see whether they are respecting the rule or not
# To do this I use the mutate() function
rule7 <- age_difference %>% 
  mutate(half_plus_seven = actor_1_age/2 + 7) %>% 
  summarise(rule_is_respected = ifelse(actor_2_age >= half_plus_seven, "YES", "NO"))

rule7

# How frequently does this rule apply in this dataset?
ruleworks <- rule7 %>% 
  group_by(rule_is_respected) %>% 
  summarize(count = n(), percent = count/1155*100)

ruleworks

# In this dataset, the rule applies around 72% of the time

# Which movie has the greatest number of love interests?
love_interests_movie <- age_difference %>% 
  group_by(movie_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

love_interests_movie

# The movie with the greatest number of love interests is Love Actually

# Which actors/ actresses have the greatest number of love interests in this dataset?
love_interests_actor1 <- age_difference %>% 
  group_by(actor_1_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

love_interests_actor1

love_interests_actor2 <- age_difference %>% 
  group_by(actor_2_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

love_interests_actor2

# Keanu Reeves has the greatest number of love interests in this dataset with 24 love interests, followed by Adam Sandler and Roger Moore. Keira Knightley is the female actress with the most love interests.

# Is the mean/median age difference staying constant over the years (1935 - 2022)?
over_time <- age_difference %>% 
  group_by(release_year) %>% 
  summarise(mean_age_diff = mean(age_diff))

over_time

plot_over_time <- over_time %>% 
  ggplot(aes( x = release_year, y = mean_age_diff)) +
  geom_line() +
  labs(x = "Release Year", y = "Age Gap", title = "Age Gap over Time") +
  theme_minimal()

plot_over_time

# It looks like over time, there is a trend that the age gap is getting smaller, with some exceptional years


# How frequently does Hollywood depict same-gender love interests?
same_gender_love <- sum(age_difference$character_1_gender == age_difference$character_2_gender)
same_gender_love

23/1155*100

# In total, Hollywood depicts same-gender love interests 23 times in the dataset, which is only 1.99% of the time

```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 < \text{Partner Age} < (\text{Your age} - 7) * 2$$ How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be commiting and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: N/A
-   Approximately how much time did you spend on this problem set: 5 hours
-   What, if anything, gave you the most trouble: part 3 of problem 5, I could not really figure it out

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
